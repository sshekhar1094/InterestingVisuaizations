{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting data\n",
    "This file is used to query the FB graph API and extract the data. \n",
    "Here the data we are extracting are all the posts on a page. Each post having its created time, the message, no of comments, likes and shares. We are not concerned with who are the users who commented, or the message in the comments, so in the API we are setting the limit to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = \"https://graph.facebook.com/v2.10/\"\n",
    "page = 'steam' # enter the page's name to get data from\n",
    "token = 'TOKEN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function queries the graph api and returns result in json format\n",
    "def req_facebook(req):\n",
    "    link = url + req + \"&access_token=\" + token\n",
    "    res = requests.get(link)\n",
    "    return res.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all posts from the page\n",
    "When we query the api it gives a set of results and also gives a link to the next set of posts. So we keep going to the next set until it is finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getAllPosts():\n",
    "    data = [];\n",
    "    # we dont actually want the comments and likes, we just want the no of likes n comments\n",
    "    results = req_facebook(page + \"/posts?fields=created_time,shares,likes.limit(0).summary(true),comments.limit(0).summary(true),message\")\n",
    "    \n",
    "    i = 0\n",
    "    while True:\n",
    "        try:\n",
    "            time.sleep(random.randint(2,4))  # just to throttle the no of requests per second\n",
    "            data.extend(results['data'])\n",
    "            next = results['paging']['next']\n",
    "            results = requests.get(next)\n",
    "            results = results.json()\n",
    "            i += 1\n",
    "            print(i, len(data))  # just to show teh progress\n",
    "        except: \n",
    "            print(\"done\")\n",
    "            break\n",
    "    return data\n",
    "    \n",
    "data = getAllPosts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now save the data using pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(data, open(\"steam_data.pkl\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
